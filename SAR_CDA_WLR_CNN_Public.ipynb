{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "SAR_CDA_WLR_CNN_Public.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "MFQLyL2UB09w",
        "7se6rvmwTWqi"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jgvinholi/sar_atr_functions/blob/master/SAR_CDA_WLR_CNN_Public.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xarc06O1718i",
        "colab_type": "text"
      },
      "source": [
        "### Retrieve all needed files:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuPbLhcyB_52",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount GDrive folder:\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8dKruoqCNh1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get files from Gdrive:\n",
        "!cp -r '/content/drive/My Drive/SAR_CD/' '/content/SAR_CD' -v "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Vf5OrGcM3vq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get updated functions from github:\n",
        "%cd /content/SAR_CD/\n",
        "!git clone https://github.com/jgvinholi/sar_atr_functions.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIRPkoHc78KA",
        "colab_type": "text"
      },
      "source": [
        "### Download and import packages:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d_qHZlr4ruK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tikzplotlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RK9Clt6YyKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U --pre tensorflow-gpu --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rg1E_cZ0B07V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "0c833112-3862-4e1d-d456-f1d20365b0d5"
      },
      "source": [
        "%cd /content/SAR_CD\n",
        "%tensorflow_version 2.x\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "class noiseStruct(object):\n",
        "  def __init__(self, speckle_var, gaussian_var, aug_negat_prob, rot_angle):\n",
        "    self.gaussian_mean = 0\n",
        "    self.speckle_mean = 1\n",
        "    self.speckle_var = speckle_var\n",
        "    self.gaussian_var = gaussian_var\n",
        "    self.aug_negat_prob = aug_negat_prob\n",
        "    self.rot_angle = rot_angle\n",
        "\n",
        "from matplotlib.image import imread\n",
        "from matplotlib import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import scipy\n",
        "import os, glob\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import initializers\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, ZeroPadding2D, Conv2D, Activation, AveragePooling2D, MaxPooling2D, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import SGD, Adam, Adadelta, Nadam\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn import metrics\n",
        "from scipy.cluster.hierarchy import fclusterdata\n",
        "import numba\n",
        "from numba import jit, njit\n",
        "import warnings\n",
        "from operator import itemgetter \n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from joblib import Parallel, delayed\n",
        "import multiprocessing\n",
        "import importlib\n",
        "\n",
        "# Import custom functions:\n",
        "import sys\n",
        "sys.path.insert(1, '/content/SAR_CD/sar_atr_functions/')\n",
        "from basefunctions import *\n",
        "from focalloss import *\n",
        "from twostepsdetect_functions import *\n",
        "# from twostepsdetect_functions import noiseStruct"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/SAR_CD\n",
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFQLyL2UB09w",
        "colab_type": "text"
      },
      "source": [
        "### Defining the predetection model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuAjBR5xB09y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def create_conv_model():\n",
        "  A = Input(shape = (3000, 2000, 1) )\n",
        "  B = Conv2D(16, (5, 5), name = 'conv0_5x5', padding = 'same', activation = 'relu')(A)\n",
        "  C = Conv2D(16, (1, 1), name = 'conv1_1x1', padding = 'same', activation = 'relu')(B)\n",
        "  C = Dropout(0.3)(C)\n",
        "  D = Conv2D(8, (3, 3), name = 'conv2_3x3', padding = 'same', activation = 'relu')(C)\n",
        "  # Out = Conv2D(1, (1, 1), name = 'out_1x1', padding = 'same', activation = 'sigmoid', bias_initializer=initializers.Constant(-4.595119) )(D)\n",
        "  Out = Conv2D(1, (1, 1), name = 'out_1x1', padding = 'same', activation = 'sigmoid', bias_initializer=tf.keras.initializers.Constant(-4.59511985013459) )(D)\n",
        "  model = Model(inputs = A, outputs = Out)\n",
        "  adam = Adam(lr = 5e-5)\n",
        "  # sgd = SGD(lr = 0.3, decay = 2e-4, momentum=0.7)\n",
        "  model.compile(optimizer = adam, loss=[binary_focal_loss(gamma = 2, alpha = 0.9999)])\n",
        "  return model \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17QEiR6CTdFC",
        "colab_type": "text"
      },
      "source": [
        "### Defining class prediction model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Elrq1_xsUaMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_classpred_model():\n",
        "  A = Input(shape = (window_size, window_size, 1) )\n",
        "  # B = BatchNormalization()(A)\n",
        "  \n",
        "  B = Conv2D(16, (3, 3), name = 'conv0_3x3', padding = 'same', activation = 'relu', kernel_initializer=tf.keras.initializers.he_normal(), bias_initializer=tf.keras.initializers.he_normal() )(A)\n",
        "  B = BatchNormalization()(B)\n",
        "  C = Conv2D(16, (3, 3), name = 'conv1_3x3', padding = 'same', activation = 'relu', kernel_initializer=tf.keras.initializers.he_normal(), bias_initializer=tf.keras.initializers.he_normal())(B)\n",
        "  C = MaxPooling2D(pool_size = (2, 2), name = 'maxp_1_2x2_s2', strides = (2, 2), padding = \"same\" )(C) # Output = 17x17\n",
        "  C = BatchNormalization()(C)\n",
        "  \n",
        "\n",
        "  D = Conv2D(32, (3, 3), name = 'conv2_3x3', padding = 'same', activation = 'relu', kernel_initializer=tf.keras.initializers.he_normal(), bias_initializer=tf.keras.initializers.he_normal())(C)\n",
        "  E = MaxPooling2D(pool_size = (2, 2), name = 'maxp_2_2x2_s2', strides = (2, 2), padding = \"same\" )(D) # Output = 9x9\n",
        "  E = BatchNormalization()(E)\n",
        "  # E = Dropout(0.3)(E)\n",
        "  \n",
        "  F = Conv2D(64, (3, 3), name = 'conv3_3x3', padding = 'same', activation = 'relu', kernel_initializer=tf.keras.initializers.he_normal(), bias_initializer=tf.keras.initializers.he_normal())(E) \n",
        "  G = MaxPooling2D(pool_size = (2, 2), name = 'maxp_3_2x2_s2', strides = (2, 2), padding = \"same\" )(F) # Output = 5x5\n",
        "  G = BatchNormalization()(G)\n",
        "  # G = Dropout(0.3)(G)\n",
        "\n",
        "  H = Conv2D(64, (3, 3), name = 'conv4_3x3', padding = 'valid', activation = 'relu', kernel_initializer=tf.keras.initializers.he_normal(), bias_initializer=tf.keras.initializers.he_normal())(G) # Output = 3x3\n",
        "  I = AveragePooling2D(pool_size = (3, 3), name = 'avp_0_3x3_s1', strides = (1, 1), padding = \"valid\" )(H) # Output = 1x1\n",
        "  I = Dropout(0.3)(I)\n",
        "  # I = BatchNormalization()(I)\n",
        "  \n",
        "\n",
        "  Out = Conv2D(1, (1, 1), name = 'conv4_1x1', padding = 'valid', activation = 'sigmoid', kernel_initializer=tf.keras.initializers.he_normal(), bias_initializer=tf.keras.initializers.Constant(-4.59511985013459))(I)\n",
        "  model = Model(inputs = A, outputs = Out)\n",
        "  adam = Adam(lr = 2e-5)\n",
        "  model.compile(optimizer = adam, loss=[binary_focal_loss(gamma = 2, alpha = 0.9)])\n",
        "  return model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFeMKSrN9MSx",
        "colab_type": "text"
      },
      "source": [
        "### Retrieve windows to train classification model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vckNvlnL16L1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " X_full_pixval_class_window, Y_class_window, X_full_pixval_class_window_noaug, Y_class_window_noaug = load_multiple_classification_gt()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuOaWXDxa0nc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d2432814-efd8-4b2a-90c5-2b885d941a05"
      },
      "source": [
        "with open(datab_imgs_path + 'classification_data/' + 'xy_classification_noaug.pkl' , 'wb') as f:  # Python 3: open(..., 'wb')\n",
        "      pickle.dump([X_full_pixval_class_window_noaug, Y_class_window_noaug], f)\n",
        "      print('saved')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPqb3yYtB094",
        "colab_type": "text"
      },
      "source": [
        "### Train the classification model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3EbCaT9ZG4H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_classpred(X_full_pixval_class_window, Y_class_window, X_full_pixval_class_window_noaug, Y_class_window_noaug, img_names):\n",
        "  n_split = int(len(img_names)/4)\n",
        "  print( str(n_split) + \"-fold.\")\n",
        "  model_classconv = [create_classpred_model() for i in range(n_split)]\n",
        "  model_classconv[0].summary()\n",
        "  scaler = StandardScaler()\n",
        "  kf = KFold(n_splits = n_split)\n",
        "  early_stopping = EarlyStopping(monitor='val_loss', patience = 20, restore_best_weights = True)\n",
        "  X_full_pixval_class_window, Y_class_window = np.asarray(X_full_pixval_class_window), np.asarray(Y_class_window)\n",
        "  X_full_pixval_class_window_noaug, Y_class_window_noaug = np.asarray(X_full_pixval_class_window_noaug), np.asarray(Y_class_window_noaug)\n",
        "  try:\n",
        "    for j, (train_index, validation_index) in enumerate( kf.split(np.arange(len(img_names) ) ) ):\n",
        "      print(train_index, validation_index)\n",
        "      x_train, x_validation = np.concatenate(X_full_pixval_class_window[train_index]), np.concatenate(X_full_pixval_class_window_noaug[validation_index])\n",
        "      y_train, y_validation = np.concatenate(Y_class_window[train_index]), np.concatenate(Y_class_window_noaug[validation_index])\n",
        "      print(x_train.shape, x_validation.shape)\n",
        "      x_train, x_validation = np.reshape(x_train, (x_train.shape[0], window_size, window_size, 1) ), np.reshape(x_validation, (x_validation.shape[0], window_size, window_size, 1) )\n",
        "      y_train, y_validation = np.reshape( y_train, (y_train.shape[0], 1, 1) ), np.reshape( y_validation, (y_validation.shape[0], 1, 1) )\n",
        "      print(x_train.shape, y_train.shape)\n",
        "      model_classconv[j].fit(x_train, y_train, epochs = 15, batch_size = 100, validation_data = (x_validation, y_validation)) \n",
        "    return model_classconv\n",
        "  except KeyboardInterrupt:\n",
        "    return model_classconv\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Rj8lNAHAB096",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_classconv = train_classpred(X_full_pixval_class_window, Y_class_window, X_full_pixval_class_window_noaug, Y_class_window_noaug, whole_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-PhY39AiYd9",
        "colab_type": "text"
      },
      "source": [
        "### Training the detection model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkpQest1B094",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_conv_kf(img_names):\n",
        "  n_split = int(len(img_names)/4)\n",
        "  model_conv = [create_conv_model() for i in range(n_split)]\n",
        "  model_conv[0].summary()\n",
        "  scaler = StandardScaler()\n",
        "  kf = KFold(n_splits = n_split)\n",
        "  j = 0\n",
        "  early_stopping = EarlyStopping(monitor='val_loss', patience = 10)\n",
        "  try:\n",
        "    for train_index, validation_index in kf.split(np.arange( len(img_names ) ) ):\n",
        "      print('Train: ' + str( itemgetter(*train_index)(img_names) ) ) \n",
        "      print('Validation: ' + str( itemgetter(*validation_index)(img_names) ) )\n",
        "      x_train, x_validation = Images_vector_norm[train_index, :, :, :], Images_vector_norm[validation_index, :, :, :]\n",
        "      y_train, y_validation = Y_full[train_index, :, :, :], Y_full[validation_index, :, :, :]\n",
        "      x_train, x_validation, y_train, y_validation = x_train.astype(np.float32), x_validation.astype(np.float32), y_train.astype(np.float32), y_validation.astype(np.float32)\n",
        "      model_conv[j].fit(x_train, y_train, epochs = 1100,\n",
        "                        batch_size = 3, validation_data = (x_validation, y_validation) )#, \n",
        "                        #callbacks = [early_stopping])  \n",
        "      j += 1\n",
        "        \n",
        "    print(\"KFold distribution.\")\n",
        "    w = np.arange(0, n_split*4)\n",
        "    for s1, s2 in kf.split(w):\n",
        "        print(s1, s2)\n",
        "    return model_conv\n",
        "\n",
        "  except KeyboardInterrupt:\n",
        "    return model_conv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmcVbp9qhpl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_conv = train_conv_kf(whole_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4gQ1BNfxDsb",
        "colab_type": "text"
      },
      "source": [
        "### Model ROC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEkRWTsrSd8S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# thresholds = np.arange(0.005, 0.15, 0.00125)\n",
        "kfold = 1\n",
        "thresholds = np.arange(0, 1.005, 0.005)\n",
        "pred_thresholds = np.linspace(0.5, 0.95, 11)\n",
        "print(thresholds, len(thresholds))\n",
        "print(pred_thresholds)\n",
        "mean_f1_scores, mean_precisions, mean_recalls, mean_fprs = roc_multiple_images(model_conv, model_classconv, whole_set[0:20], whole_set, thresholds, pred_thresholds, 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7hF_NCT3fHv",
        "colab_type": "text"
      },
      "source": [
        "### Load/save predetection model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPS7IjMWyv5U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save_modelconv(model_conv, \"convarch3_lr5em5_1100epochs_focal_KF_6models\", 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5_dUFF13kG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_conv = load_modelconv(\"convarch3_lr5em5_1100epochs_focal_KF_6models\", 1)\n",
        "# model_conv = load_modelconv(\"convarch3_lr5em5_1100epochs_focal_KF\", 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZE8ZAyt2b0XJ",
        "colab_type": "text"
      },
      "source": [
        "### Load/save classification model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ycn4DiS04NBJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save_modelconv(model_classconv, \"classarch16_lr2em5_15epoch_focal_beta2alpha0p9_0p7noise_allcenteredtechnique_gaussiannoise_6models\", 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goSNCjqN4OiI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model_classconv = load_modelconv(\"classarch16_lr2em5_15epoch_focal_beta2alpha0p9_0p7noise_allcenteredtechnique_gaussiannoise\", 1)\n",
        "model_classconv = load_modelconv(\"classarch16_lr2em5_15epoch_focal_beta2alpha0p9_0p7noise_allcenteredtechnique_gaussiannoise_6models\", 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2_sQ5WOAAi4",
        "colab_type": "text"
      },
      "source": [
        "### Predict all images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "EstwYblnB0-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for h in np.arange(0.8+0.02, 0.9, 0.02):\n",
        "  print(h)\n",
        "  for i in np.arange(0, 21, 4):\n",
        "    detected_targets, false_positives = predict_and_save(model_conv, model_classconv, whole_set[i:i+4], detect_thresh = 0.68, classif_thresh = [h], save=1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}